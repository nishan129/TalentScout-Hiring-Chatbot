{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86883369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac826df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc09cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(api_key=groq_api,model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11017a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_level = 3\n",
    "technology_stack = \"AI and Machine learning\"\n",
    "key_technologies =  \"Python Machine learning deep learning genrative ai\"\n",
    "role_type = \"AI resercher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "615acd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = f\"\"\"\n",
    "You are a technical interview question generator bot for TalentScout.\n",
    "\n",
    "Your task is to generate **one** direct, relevant, and practical technical interview question at a time based on:\n",
    "- **Technology Stack**: {technology_stack}\n",
    "- **Experience Level**: {experience_level}\n",
    "- **Key Technologies**: {key_technologies}\n",
    "- **Role Type**: {role_type}\n",
    "\n",
    "### Question Generation Rules:\n",
    "1. Only generate **one** question per response.\n",
    "2. Use a mix of formats:\n",
    "   - Multiple Choice (MCQ)\n",
    "   - Short Answer\n",
    "   - Coding Task\n",
    "   - Scenario-Based\n",
    "   - System Design (only for Senior level)\n",
    "3. Match difficulty to experience:\n",
    "   - **Junior (0–2 yrs)**: Basics, syntax, simple logic\n",
    "   - **Mid (2–5 yrs)**: Problem solving, best practices\n",
    "   - **Senior (5+ yrs)**: System design, architecture, tech leadership\n",
    "4. Focus only on the provided tech stack and role.\n",
    "5. Question should be clear, concise, and job-relevant.\n",
    "\n",
    "### Output Format:\n",
    "\n",
    "[Generated Question Here]\n",
    "\n",
    "\n",
    "Do not generate explanations or multiple questions. Return only one question per response.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21cd2b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_template),\n",
    "        (\"user\",\"Answer:{Answer}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b321eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gererate_response(Answer):\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt | llm | output_parser\n",
    "    \n",
    "    answer = chain.invoke({\"Answer\":Answer})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c150cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the differences between supervised, unsupervised, and reinforcement learning, and provide an example of a real-world application for each. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gererate_response(Answer=\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0aa8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb576cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b743e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = chain.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Tell me questions\"),\n",
    "        AIMessage(content=\"Given a dataset with imbalanced classes, describe two techniques you would use to address this issue during the training of a deep learning model and explain the rationale behind your choices.\"),\n",
    "        HumanMessage(content=\"first we balanced the classes and than create model\"),\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db1c4125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a text dataset, explain how you would use a Generative Adversarial Network (GAN) to generate new, synthetic text samples that resemble the style and content of the original dataset.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658a32e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0879b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7fcf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(api_key=api_key,model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfe940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"You are a sentiment analysis chatbot that evaluates users' answers to technical questions.\n",
    "\n",
    "Your job is to:\n",
    "1. Analyze the user’s answer and determine their confidence level.\n",
    "2. Classify the answer into one of the following:\n",
    "   - **Confident** – clear, assertive, or well-explained answers.\n",
    "   - **Confused** – vague, hesitant, or unsure answers (e.g., “maybe,” “I think,” “not sure”).\n",
    "   - **Neutral** – short, generic, or unclear responses that are neither confident nor confused.\n",
    "\n",
    "Output the result as a short, conversational sentence:\n",
    "- If confident: **\"You seem very confident.\"**\n",
    "- If confused: **\"You seem a bit confused.\"**\n",
    "- If neutral: **\"Your answer feels neutral.\"**\n",
    "\n",
    "Do not include any explanations or extra text.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b194fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f37ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
